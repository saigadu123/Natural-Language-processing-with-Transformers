# Hello Transformers

## Encoder Decoder Framework

The encoder-decoder framework is a neural network architecture commonly used for sequence-to-sequence tasks like translation and summarization. The encoder processes the input sequence, compressing it into a fixed-length representation (context vector) that captures its essential information. The decoder takes this context vector and generates the output sequence, one element at a time. Attention mechanisms are often added to improve performance by dynamically focusing on different parts of the input. This framework is widely employed in natural language processing (NLP) and other tasks requiring input-output mapping.

![Encoder-Decoder](C:\One-Drive\OneDrive-redence\Natural-Language-processing-with-Transformers\images\Encoder-Decoder.png)

